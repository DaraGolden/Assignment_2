{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Writing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "The wet_asphalt_smooth folder contains 79404 files.\n",
      "The wet_concrete_smooth folder contains 66955 files.\n",
      "The wet_gravel folder contains 36515 files.\n",
      "Test\n",
      "The wet_asphalt_smooth folder contains 79 files.\n",
      "The wet_concrete_smooth folder contains 160 files.\n",
      "The wet_gravel folder contains 2351 files.\n",
      "Validation\n",
      "The wet_asphalt_smooth folder contains 821 files.\n",
      "The wet_concrete_smooth folder contains 821 files.\n",
      "The wet_gravel folder contains 821 files.\n",
      "Total wet_asphalt_smooth: 80304\n",
      "Total wet_concrete_smooth: 67936\n",
      "Total wet_gravel: 39687\n",
      "\n",
      "Ideal split for 80% train, 10% test, 10% validation:\n",
      "Train: 31750.0 files\n",
      "Test: 3969.0 files\n",
      "Validation: 3969.0 files\n"
     ]
    }
   ],
   "source": [
    "# Function used to count number of samples in each class in each set\n",
    "def count_files_in_subfolders(parent_folder):\n",
    "    subfolders = ['wet_asphalt_smooth', 'wet_concrete_smooth', 'wet_gravel']\n",
    "    wet_asphalt_smooth = 0\n",
    "    wet_concrete_smooth = 0\n",
    "    wet_gravel = 0\n",
    "    for subfolder in subfolders:\n",
    "        path = os.path.join(parent_folder, subfolder)\n",
    "        if os.path.exists(path):\n",
    "            count = sum([len(files) for r, d, files in os.walk(path)])\n",
    "            print(f\"The {subfolder} folder contains {count} files.\")\n",
    "            \n",
    "            if subfolder == 'wet_asphalt_smooth':\n",
    "                wet_asphalt_smooth += count\n",
    "            if subfolder == 'wet_concrete_smooth':\n",
    "                wet_concrete_smooth += count\n",
    "            if subfolder == 'wet_gravel':\n",
    "                wet_gravel += count\n",
    "        else:\n",
    "            print(f\"The {subfolder} folder does not exist in the specified path.\")\n",
    "    return [wet_asphalt_smooth, wet_concrete_smooth, wet_gravel]\n",
    "\n",
    "# Prints out the number of files in each folder and accumulates them\n",
    "print('Train')\n",
    "train_total = count_files_in_subfolders(\"Group_9_wet_smooth/Train\")\n",
    "\n",
    "print('Test')\n",
    "test_total = count_files_in_subfolders(\"Group_9_wet_smooth/Test\")\n",
    "\n",
    "print('Validation')\n",
    "valid_total = count_files_in_subfolders(\"Group_9_wet_smooth/Valid\")\n",
    "\n",
    "grand_total = np.array(train_total) + np.array(test_total) + np.array(valid_total)\n",
    "\n",
    "print(f'Total wet_asphalt_smooth: {grand_total[0]}')\n",
    "print(f'Total wet_concrete_smooth: {grand_total[1]}')\n",
    "print(f'Total wet_gravel: {grand_total[2]}')\n",
    "\n",
    "# Calculate the ideal based on the minority class\n",
    "ideal_train = round(np.min(grand_total) * 0.8,0)\n",
    "ideal_test = round(np.min(grand_total) * 0.1,0)\n",
    "ideal_valid = round(np.min(grand_total) * 0.1,0)\n",
    "\n",
    "print(f\"\\nIdeal split for 80% train, 10% test, 10% validation:\")\n",
    "print(f\"Train: {ideal_train} files\")\n",
    "print(f\"Test: {ideal_test} files\")\n",
    "print(f\"Validation: {ideal_valid} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a file from old path and writes to new path\n",
    "def read_and_write_img(old_path,new_path):\n",
    "    try:\n",
    "        img = cv2.imread(old_path)\n",
    "        img = cv2.resize(img, (96, 64), interpolation=cv2.INTER_CUBIC)\n",
    "        cv2.imwrite(new_path, img)\n",
    "    except:\n",
    "        print(f'failed on {old_path}')\n",
    "\n",
    "# Takes in old and new dataset folders, the names of the classes and the number of files to be written to the test and validation sets\n",
    "def balance_dataset(old_dataset_folder, new_dataset_folder, classes, test_valid_count):\n",
    "    sets = ['Train', 'Test', 'Valid']\n",
    "    file_lists = {}\n",
    "\n",
    "    # Load and shuffle file lists, shuffling done to ensure excess files taken from old training sets are random.\n",
    "    for set_name in sets:\n",
    "        for class_name in classes:\n",
    "            old_path = os.path.join(old_dataset_folder, set_name, class_name)\n",
    "            files = os.listdir(old_path)\n",
    "            random.shuffle(files)\n",
    "            file_lists[(set_name, class_name)] = files\n",
    "\n",
    "    # Process Validation and Test sets\n",
    "    for set_name in ['Valid', 'Test']:\n",
    "        print(set_name) # For debugging purposes\n",
    "        for class_name in classes:\n",
    "            print(class_name)\n",
    "            new_path = os.path.join(new_dataset_folder, set_name, class_name)\n",
    "            os.makedirs(new_path, exist_ok=True)\n",
    "\n",
    "            # While there are not enough files in the new test or valid folder for a given class\n",
    "            # This will try take a file from the old test/valid folder and if it has run out it will \n",
    "            # instead take the extra it needs from the training class\n",
    "            while len(os.listdir(new_path)) < test_valid_count:\n",
    "                if len(file_lists[(set_name, class_name)]) > 0:\n",
    "                    file_name = file_lists[(set_name, class_name)].pop(0)\n",
    "                    old_img_path = os.path.join(old_dataset_folder, set_name, class_name, file_name)\n",
    "                    new_img_path = os.path.join(new_path, file_name)\n",
    "\n",
    "                    read_and_write_img(old_img_path,new_img_path)\n",
    "                elif len(file_lists[('Train', class_name)]) > 0:\n",
    "                    file_name = file_lists[('Train', class_name)].pop(0)\n",
    "                    old_img_path = os.path.join(old_dataset_folder, 'Train', class_name, file_name)\n",
    "                    new_img_path = os.path.join(new_path, file_name)\n",
    "\n",
    "                    read_and_write_img(old_img_path,new_img_path)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    print('Train')\n",
    "    # Process Train set\n",
    "    for class_name in classes:\n",
    "        print(class_name)\n",
    "        new_path = os.path.join(new_dataset_folder, 'Train', class_name)\n",
    "        os.makedirs(new_path, exist_ok=True)\n",
    "\n",
    "        while file_lists[('Train', class_name)]:\n",
    "            file_name = file_lists[('Train', class_name)].pop(0)\n",
    "            old_img_path = os.path.join(old_dataset_folder, 'Train', class_name, file_name)\n",
    "            new_img_path = os.path.join(new_path, file_name)\n",
    "            read_and_write_img(old_img_path,new_img_path)\n",
    "\n",
    "old_dataset_folder = \"Group_9_wet_smooth\"\n",
    "new_dataset_folder = \"New_dataset\"\n",
    "classes = ['wet_asphalt_smooth', 'wet_concrete_smooth', 'wet_gravel']\n",
    "test_valid_count = 3969\n",
    "\n",
    "# Commented out as this has already been completed.\n",
    "# balance_dataset(old_dataset_folder, new_dataset_folder, classes, test_valid_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataset given img directories\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dirs, transform=None):\n",
    "        self.img_dirs = img_dirs\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        # Utilises the enumerate as the label\n",
    "        for i, img_dir in enumerate(img_dirs):\n",
    "            for img_name in os.listdir(img_dir):\n",
    "                img_path = os.path.join(img_dir, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.images[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "# Creates train, validation and test loaders\n",
    "def create_data_loaders(train_dirs, valid_dirs, test_dirs, batch_size, train_samples):\n",
    "    # Conversion to tensor also normalises images between 0 and 1\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Creates datasets\n",
    "    train_datasets = ImageDataset(train_dirs, transform=transform)\n",
    "    valid_datasets = ImageDataset(valid_dirs, transform=transform)\n",
    "    test_datasets = ImageDataset(test_dirs, transform=transform)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Given the massive imbalance in the samples in each class a WeightedRandomSampler is used to allow the model to learn properly\n",
    "    # Weights len is of len(num_samples) to give each a weight.\n",
    "    weights_len = len(os.listdir(train_dirs[0])) + len(os.listdir(train_dirs[1])) + len(os.listdir(train_dirs[2]))\n",
    "    sampler_weights = np.zeros(weights_len)\n",
    "\n",
    "    # Pytorch takes all the values in a weighted random sampler and normalises them between 0 and 1 so the sampler_weights array does not have to sum to 1\n",
    "    # All of the samples for each class are given a weight of 1 / Class_num_samples which leads to roughly equal numbers of each class being returned each epoch\n",
    "    sampler_weights[:len(os.listdir(train_dirs[0]))] = 1/len(os.listdir(train_dirs[0]))\n",
    "    sampler_weights[len(os.listdir(train_dirs[0])):-len(os.listdir(train_dirs[2]))] = 1/len(os.listdir(train_dirs[1]))\n",
    "    sampler_weights[-len(os.listdir(train_dirs[2])):] = 1/len(os.listdir(train_dirs[2]))\n",
    "\n",
    "    # sampler is created with the weights, a configurable number of samples per epoch and replacement enabled.\n",
    "    sampler = WeightedRandomSampler(weights=sampler_weights, num_samples=train_samples, replacement=True)\n",
    "    \n",
    "    # Loaders are created from datasets with configurable batch_size\n",
    "    train_loader = DataLoader(train_datasets, batch_size=batch_size, sampler=sampler)\n",
    "    valid_loader = DataLoader(valid_datasets, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_datasets, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, test_loader, epochs, optimizer, criterion, title, train_samples, patience=5):\n",
    "    \n",
    "    # All of the variables needed to train a model are passed to the train model function to allow it to be reused.\n",
    "\n",
    "    # GPU utilised for training.\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Timestamp taken for saving of models and stats of each training run\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    train_loss_list, train_acc_list , valid_loss_list, valid_acc_list , test_loss_list , test_acc_list  = [],[],[],[],[],[]     \n",
    "    best_valid_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Makes folder for logging\n",
    "    os.makedirs(f'models/{timestamp}', exist_ok=True)\n",
    "    # Opens csv to log Loss and Accuracy\n",
    "    with open(f'models/{timestamp}/training_stats.csv', mode='w', newline='') as csvfile:\n",
    "        fieldnames = ['Epoch', 'Train Loss', 'Train Acc', 'Valid Loss', 'Valid Acc', 'Test Loss', 'Test Acc']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            model.train()\n",
    "            # Runs through all values in trainloader learns and accumulates loss and accuracy\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels = labels.to(torch.long)  \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Accumulates loss and accuracy of validation set\n",
    "            valid_loss = 0.0\n",
    "            valid_correct = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in valid_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    labels = labels.to(torch.long)  \n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    valid_loss += loss.item() * images.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    valid_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Accumulates loss and accuracy of test set\n",
    "            test_loss = 0.0\n",
    "            test_correct = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    labels = labels.to(torch.long)  \n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    test_loss += loss.item() * images.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Gets average loss and average accuracy for train, validation and test\n",
    "            # Train_samples = configurable length of the trainloader\n",
    "            train_loss /= train_samples;                train_acc = train_correct / train_samples\n",
    "            valid_loss /= len(valid_loader.dataset);    valid_acc = valid_correct / len(valid_loader.dataset)\n",
    "            test_loss /= len(test_loader.dataset);      test_acc = test_correct / len(test_loader.dataset)\n",
    "\n",
    "            train_loss_list.append(train_loss),train_acc_list.append(train_acc),valid_loss_list.append(valid_loss),\n",
    "            valid_acc_list.append(valid_acc),test_loss_list.append(test_loss),test_acc_list.append(test_acc)\n",
    "\n",
    "            print(f'Epoch: {epoch}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "            writer.writerow({'Epoch': epoch,\n",
    "                             'Train Loss': train_loss,\n",
    "                             'Train Acc': train_acc,\n",
    "                             'Valid Loss': valid_loss,\n",
    "                             'Valid Acc': valid_acc,\n",
    "                             'Test Loss': test_loss,\n",
    "                             'Test Acc': test_acc,})\n",
    "            \n",
    "            # Updates best loss achieved, resets patience counter and saves the model\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(model.state_dict(), f'models/{timestamp}/{epoch}.chkpt')\n",
    "            # else increments the patience counter and if it has reached a limit stops the training.\n",
    "            # Patience counter is implemented so if the model is overfitting resources will not be wasted.\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print('Early stopping')\n",
    "                    break\n",
    "        \n",
    "        # Plots the models loass and accuracy.\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_loss_list, label='Train')\n",
    "        plt.plot(valid_loss_list, label='Valid')\n",
    "        plt.plot(test_loss_list, label='Test')\n",
    "        plt.title(f'{title} - Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_acc_list, label='Train')\n",
    "        plt.plot(valid_acc_list, label='Valid')\n",
    "        plt.plot(test_acc_list, label='Test')\n",
    "        plt.title(f'{title} - Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of: \n",
    "# Woo, Sanghyun, Jongchan Park, Joon-Young Lee, and In So Kweon. \n",
    "# \"Cbam: Convolutional block attention module.\" \n",
    "# In Proceedings of the European conference on computer vision (ECCV), pp. 3-19. 2018.\n",
    "# implemented by Peachypie98 on github at the following url https://github.com/Peachypie98/CBAM\n",
    "class CAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=self.channels, out_features=self.channels//self.r, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=self.channels//self.r, out_features=self.channels, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = F.adaptive_max_pool2d(x, output_size=1)\n",
    "        avg = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        b, c, _, _ = x.size()\n",
    "        linear_max = self.linear(max.view(b,c)).view(b, c, 1, 1)\n",
    "        linear_avg = self.linear(avg.view(b,c)).view(b, c, 1, 1)\n",
    "        output = linear_max + linear_avg\n",
    "        output = F.sigmoid(output) * x\n",
    "        return output\n",
    "\n",
    "class SAM(nn.Module):\n",
    "    def __init__(self, bias=False):\n",
    "        super(SAM, self).__init__()\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = torch.max(x,1)[0].unsqueeze(1)\n",
    "        avg = torch.mean(x,1).unsqueeze(1)\n",
    "        concat = torch.cat((max,avg), dim=1)\n",
    "        output = self.conv(concat)\n",
    "        output = F.sigmoid(output) * x \n",
    "        return output \n",
    "    \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.sam = SAM(bias=False)\n",
    "        self.cam = CAM(channels=self.channels, r=self.r)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cam(x)\n",
    "        output = self.sam(output)\n",
    "        return output + x\n",
    "\n",
    "# RCNET architecture implemented from the paper:\n",
    "# Dewangan, Deepak Kumar, and Satya Prakash Sahu. \n",
    "# \"RCNet: road classification convolutional neural networks for intelligent vehicle system.\" \n",
    "# Intelligent Service Robotics 14, no. 2 (2021): 199-214.\n",
    "\n",
    "# Added additional attention layers based on the CBAM architecture to improve performance\n",
    "class RCNet_attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RCNet_attention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.CBAM1 = CBAM(64,4)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout()\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.conv7 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv8 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.CBAM2 = CBAM(128,4)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(12288, 256, bias=True)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 256, bias=True)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 3, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.CBAM1(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.upsample1(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.CBAM2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = [\"New_dataset/Train/wet_asphalt_smooth\", \"New_dataset/Train/wet_concrete_smooth\", \"New_dataset/Train/wet_gravel\"]\n",
    "valid_dirs = [\"New_dataset/Valid/wet_asphalt_smooth\", \"New_dataset/Valid/wet_concrete_smooth\", \"New_dataset/Valid/wet_gravel\"]\n",
    "test_dirs = [\"New_dataset/Test/wet_asphalt_smooth\", \"New_dataset/Test/wet_concrete_smooth\", \"New_dataset/Test/wet_gravel\"]\n",
    "batch_size = 128\n",
    "train_samples = 100000 # total number of samples in the train set\n",
    "# train_samples = 20000\n",
    "train_loader, valid_loader, test_loader = create_data_loaders(train_dirs, valid_dirs, test_dirs, batch_size, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Train Loss: 0.6935, Train Acc: 0.6881, Valid Loss: 0.4803, Valid Acc: 0.8049, Test Loss: 0.4721, Test Acc: 0.8149\n",
      "Epoch: 2/50, Train Loss: 0.4575, Train Acc: 0.8202, Valid Loss: 0.8056, Valid Acc: 0.6935, Test Loss: 0.8015, Test Acc: 0.6926\n",
      "Epoch: 3/50, Train Loss: 0.4109, Train Acc: 0.8394, Valid Loss: 0.4112, Valid Acc: 0.8313, Test Loss: 0.3926, Test Acc: 0.8459\n",
      "Epoch: 4/50, Train Loss: 0.3814, Train Acc: 0.8518, Valid Loss: 0.5109, Valid Acc: 0.8028, Test Loss: 0.4816, Test Acc: 0.8183\n",
      "Epoch: 5/50, Train Loss: 0.3615, Train Acc: 0.8597, Valid Loss: 0.5353, Valid Acc: 0.7895, Test Loss: 0.5008, Test Acc: 0.8062\n",
      "Epoch: 6/50, Train Loss: 0.3373, Train Acc: 0.8712, Valid Loss: 0.3579, Valid Acc: 0.8576, Test Loss: 0.3324, Test Acc: 0.8776\n",
      "Epoch: 7/50, Train Loss: 0.3187, Train Acc: 0.8778, Valid Loss: 0.4466, Valid Acc: 0.8316, Test Loss: 0.3853, Test Acc: 0.8576\n",
      "Epoch: 8/50, Train Loss: 0.3015, Train Acc: 0.8849, Valid Loss: 0.3588, Valid Acc: 0.8545, Test Loss: 0.3142, Test Acc: 0.8805\n",
      "Epoch: 9/50, Train Loss: 0.2863, Train Acc: 0.8923, Valid Loss: 0.3175, Valid Acc: 0.8769, Test Loss: 0.2854, Test Acc: 0.8925\n",
      "Epoch: 10/50, Train Loss: 0.2790, Train Acc: 0.8953, Valid Loss: 0.3055, Valid Acc: 0.8825, Test Loss: 0.2798, Test Acc: 0.8961\n",
      "Epoch: 11/50, Train Loss: 0.2628, Train Acc: 0.9002, Valid Loss: 0.5257, Valid Acc: 0.7912, Test Loss: 0.5255, Test Acc: 0.7888\n",
      "Epoch: 12/50, Train Loss: 0.2526, Train Acc: 0.9052, Valid Loss: 0.2875, Valid Acc: 0.8874, Test Loss: 0.2658, Test Acc: 0.9015\n",
      "Epoch: 13/50, Train Loss: 0.2454, Train Acc: 0.9073, Valid Loss: 0.4334, Valid Acc: 0.8246, Test Loss: 0.4255, Test Acc: 0.8271\n",
      "Epoch: 14/50, Train Loss: 0.2367, Train Acc: 0.9111, Valid Loss: 0.2702, Valid Acc: 0.8949, Test Loss: 0.2611, Test Acc: 0.9025\n",
      "Epoch: 15/50, Train Loss: 0.2319, Train Acc: 0.9126, Valid Loss: 0.2645, Valid Acc: 0.8981, Test Loss: 0.2381, Test Acc: 0.9144\n",
      "Epoch: 16/50, Train Loss: 0.2282, Train Acc: 0.9134, Valid Loss: 0.3067, Valid Acc: 0.8722, Test Loss: 0.3059, Test Acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# model = RCNet()\n",
    "model = RCNet_attention()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),0.00001,)\n",
    "train_model(model,train_loader,valid_loader,test_loader,50,optimizer,criterion,'First Training run of RCNet no attention', train_samples, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and accuracy curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
